# 联系方式
* 手机：13683132915
* Email: hudanyun.sheng@outlook.com

# 个人信息
* 盛胡丹筠/女/1993
* 硕士/佛罗里达大学电子与计算机工程
* 工作年限：4年
* Github：https://github.com/DannieSheng
* 期望职位：数据科学家
* 期望薪资：税前月薪25k~40k
* 期望城市：北京

# 教育经历
* 佛罗里达大学 
    * 电子与计算机工程硕士（2018.01 - 2019.12）
    * 硕士论文：基于高光谱图像的柳枝草基因型分类 (Switchgrass Genotype Classification using Hyperspectral Imagery)
    * 工业系统工程硕士（2016.01 - 2017.12）
* 同济大学
    * 物理学学士（2011.09 - 2015.06）
    * 毕业论文： X射线多层膜KB成像的强度均匀性校正

# 工作经历
## Zenni Optical (2023.06 ~ 2023.01)
数据科学家 (其中8月前是兼职)
### OCR 项目（支持日本市场的眼镜处方自动识别）
- 已有内部开发用于眼镜处方自动解析的工具（OptiReader），该工具的FastAPI服务已经部署在生产环境并且投入使用，可以支持北美市场的处方自动解析。需要需要支持VR眼镜在日本市场的上线。
    - Google Document AI API's Form Parser  （付费，最初解决方案，当下仅仅用于PDF格式的输入）
    - Donut ([OCR-free Document Understanding Transformer](https://arxiv.org/abs/2111.15664))
        - Donut采用了一种创新的OCR-free VDU模型，即无需OCR的文档理解模型。Donut采用了Transformer架构，并使用交叉熵损失进行预训练。尽管概念上简单，Donut在实验和分析中表现出色，成为OCR-free VDU领域的领先模型，同时在速度和准确性方面取得了最先进的性能。
        - Donut本身在英文、中文、汉语、日语的数据集上预训练
- 经调研，日本市场主流处方有两种：与北美的眼镜处方除了语言不同外没有差别的横版处方；以及北美市场几乎没有出现的竖版处方
- 调整现有模型，使得现有模型可以正常处理处方中有日语，并且也能处理竖版处方
- 通过调研，竖版处方在日本处方中占较大比重（超过50%），因此为正常解析日本市场的处方，模型调整是必要的；但是日本市场占整个市场的比重比较小，因此花费时间精力重新训练Donut模型（标记数据、训练、调优等等）过于繁琐和不必要
- 为API增加用户输入来表示处方数据来源(`country_of_origin`)，以便于根据来源来区分后续步骤
- 对所有来自日本的处方(`country_of_origin=JP`)，先通过后处理已有Donut模型的输出来判断处方是否是横版
    - 若为横版处方，则正常输出结果
    - 若为竖版处方，则增加一个利用Google Form Parser的步骤，利用现有工具直接解析处方
- 经部署在Dev环境测试后部署上线生产环境投入使用，正常支持日本市场。

### 模糊度检测图像质量测评模块
- 从之前生产环境收集到的数据来看，图像本身的质量会极大程度影响处方解析的成功率与准确率 。
    - 已有内部开发的图像质量测评模块，该模块可以检测图像的方向(orientation)。但是仍然需要一个模块来评估图像的模糊程度。
- 设计并训练一个多任务的图像质量评估模块，可以同时评估图像的方向以及模糊程度
- 已有图像方向检测模块是基于ConvNeXt V2 ([OCR-free Document Understanding Transformer](https://arxiv.org/abs/2111.15664))，并且拥有优秀表现。
    - ConvNeXt V2 基于ConvNe模型进行了改进，引入了全卷积的自编码器架构和新的全局响应归一化（GRN）层。是结合了自监督学习技术和架构改进的设计。
    - ConvNeXt V2 在图像分类、目标检测和分割等多个领域都表现出色。特别是在 ImageNet 分类、COCO 目标检测和ADE20K 分割等基准任务上，ConvNeXt V2 在性能上有着显著的提升。
        - 最后，ConvNeXt V2 提供了多个规模的预训练模型，从高效的 3.7M 参数 Atto 模型到 650M 参数的 Huge 模型，都在 ImageNet 上取得了令人瞩目的性能。
    - ConvNeXt V2 的架构改进包括引入全卷积的自编码器框架，这为模型提供了更好的特征学习和表达能力。此外，新的全局响应归一化（GRN）层被添加，以增强通道间特征竞争，从而进一步提高模型的性能。
- 数据标记：
    - 在已有处方解析标签的数据集（用label studio标记）上，通过制定相关标记规则，来产生针对模糊度的标签
    - 但是面临的巨大挑战是，已有数据中，`高度模糊` (`Blurry`) 所占比例相比`Fine` 来说太小，造成类别严重不均衡，不利于分类模型训练。
    - 通过查询生产数据库来收集更多 `Blurry` 数据
        - 包含利用 Streamlit 开发可视化小程序来辅助数据标记  
- 模型设计
    - 针对图像模糊度检测（分类）的模型也选用了ConvNeXt V2作为backbone，选用了hugging face上的[timm/convnextv2_base.fcmae_ft_in22k_in1k_384]
(https://huggingface.co/timm/convnextv2_base.fcmae_ft_in22k_in1k_384)。
    - 损失函数选了 `Poly1FocalLoss`
- 模型表现：
    - `Fine` 准确率：96.2% `Blurry` 准确率：89.6% 
    - `Fine` F1: 95.4% `Blurry` F1 88.9% 

## 德克萨斯西南医学中心 (2021.09 ~ 2023.05)
数据科学家
### mask RCNN 项目
- 已有基于keras的mask R-CNN的模型，用于检测非小细胞肺癌(Non-Small Cell Lung Cancer)的染色病理图像中常见的6类细胞核，并同时进行分割和分类
- 通过迁移学习，微调一个用于检测乳腺癌的染色病理图像中常见的7类细胞核，并同时进行分割和分类
- 犹豫数据的标签存在一定问题，不能直接用于训练：
    - Mask R-CNN的需要同时有边界框和（位置）、类别标签、以及像素级别的掩码标签
    - 真实数据的标签有部分缺失———有些数据缺失了掩码标签，有些数据缺失了类别标签（`Unlabeled`）；经统计，这部分标签缺失占总数据的20%（直接舍弃会造成数据浪费）
- 通过重新设计mask R-CNN的损失函数，使得计算损失的时可以有选择地忽略标签有缺失的样本
    - 具体来说，缺少分类标签的样本不参与分类损失的计算，缺少掩码标签的样本不参与掩码损失的计算
-  获得了一个基于PyTorch框架的、适用于检测乳腺癌的染色病理图像中常见的7类细胞核，并同时进行分割和分类的mask R-CNN模型（检测率82.5%，7分类准确率82.0%）
- Mask R-CNN选择原因：
    - Mask R-CNN在实例分割任务中具有高精确度和准确性。在肿瘤细胞核检测中，准确地定位和分割细胞核是至关重要的。
    - Mask R-CNN不仅能够检测物体的边界框，还能生成每个对象实例的详细掩码。对于肿瘤细胞核检测，掩码的生成能力可以提供更详细和精细的信息，有助于更准确地理解细胞核的形状和结构。
    - 基于PyTorch的Mask R-CNN具有灵活性和可调整性，可以根据任务的需求进行修改和调整。这使得它非常适合处理不同形状、尺寸和密度的肿瘤细胞核。
    - Mask R-CNN 是一个受欢迎的模型，有一个庞大而先进的社区支持，拥有丰富的资源、文档和预训练模型。这有助于简化开发过程，加速模型训练和优化过程。

## 唐纳德丹福思植物科学中心 (2020.02 ~ 2021.09)
数据科学研究员
### plantCV 项目

## 佛罗里达大学医疗中心 (2019.05 ~ 2019.08)
数据科学实习生

# 技能清单
* 数学和统计学基础：具备扎实的数学原理、概率论和统计学基础，并将这些概念应用于实际情境
* 人工智能和机器学习：机器学习、深度学习和计算机视觉，开发和部署复杂的深度学习和机器学习模型
* 深度学习框架或平台：PyTorch、spaCy、TensorFlow、Keras、Hugging Face
* 编程语言和工具：Python (包括NumPy、Pandas、Scikit-learn、SciPy、ggplot2、Seaborn、OpenCV、Streamlit和plotly等库)、 MATLAB
* DevOps及云技术：Google Cloud、熟练使用Docker进行容器化
* 版本控制：Git
* 数据库和数据存储：MySQL、CloudSQL、BigQuery
* Web开发：Flask框架、FastAPI框架、HTML、CSS、Ajax和JavaScript
* 数据分析：SQL、MS Office、Tableau
* 其他领域：电子健康档案（EHR）数据分析
